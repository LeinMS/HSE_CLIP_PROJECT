# CLIP Analysis for Multimodal Learning

This project explores the integration of the CLIP model into AI applications, analyzing its architecture, training methodology, performance on CIFAR-10, and limitations.

## Overview

- **Goal:** Understand and utilize CLIP for multimodal learning.
- **Key Features:**
  - Dual encoders (Vision Transformer & Transformer) for shared image-text embeddings.
  - Contrastive learning on 400M image-text pairs for strong zero-shot capabilities.
  - Achieved **88.8% accuracy** on CIFAR-10 but struggles with visually similar classes.

